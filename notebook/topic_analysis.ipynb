{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About\n",
    "This notebook works through extracting parts of speech, the entities, the noun chunks, and the topic vector and string. These features may be useful to more accurately categorize arbitrary text blobs.\n",
    "\n",
    "[Language Model](#Language-Model)  \n",
    "[Corpra](#Corpra)  \n",
    "[Topic Modeling](#Topic-Modeling)  \n",
    "[Parts of speech](#Parts-of-Speech)  \n",
    "[Entity Detection](#Entity-Detection)  \n",
    "[Tokenize](#Tokenize)  \n",
    "[Topic Vector](#Topic-Vector)  \n",
    "[Topic String](#Topic-String)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 524 ms, sys: 144 ms, total: 668 ms\n",
      "Wall time: 503 ms\n"
     ]
    }
   ],
   "source": [
    "from tool import import_dir; import_dir(\"../\")\n",
    "%time from src.lib import nlp as libnlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Language Model\n",
    "I am using the [medium english model](https://spacy.io/models/en#en_core_web_md) provided by spacy. I could likely improve results by using one of the larger models, but I chose the medium to work in a memory constrained environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17 s, sys: 544 ms, total: 17.5 s\n",
      "Wall time: 17.6 s\n"
     ]
    }
   ],
   "source": [
    "%time (nlp, keys, vectors) = libnlp.load_model(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Corpra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 52.2 ms, sys: 1.98 ms, total: 54.2 ms\n",
      "Wall time: 54 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "doc = nlp(u\"\"\"\n",
    "    Explosions will continually shake the earth\n",
    "    Radiated robot men will stalk each other\n",
    "    The rich and the chosen will watch from space platforms\n",
    "    Dante's Inferno will be made to look like a children's playground\n",
    "    The sun will not be seen and it will always be night\n",
    "    Trees will die\n",
    "\"\"\".strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Topic Modeling\n",
    "The primary feature used to derive a topic is the \"topic vector\". The topic vector is the average of the word vectors. When converting from vector space to text, I am finding a word in the models vocabulary whose vector is closest to the topic vector. The closest word might not actually be close to the topic vector, but could be a limitation of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Parts of Speech\n",
    "This data needs to be transformed to make it friendlier for machine learning work.\n",
    "\n",
    "One possible solution is a part of speech hasmap. This could be represented as a python dictionary where the keys are the string text for the part of speech and the value is the number of times it appears in a sample. \n",
    "\n",
    "This structure should include every possible key to allow allow corpra to be compared.\n",
    "```\n",
    "{\n",
    "    \"NOUN\": <number of occurances>,\n",
    "    \"PRON\": <number of occurances>,\n",
    "    ...\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# proof of concept for creating a pos hash\n",
    "def pos_hash(pos):\n",
    "    _hash = {}\n",
    "    for tag in pos:\n",
    "        if tag not in _hash:\n",
    "            _hash[tag] = 1\n",
    "        else: \n",
    "            _hash[tag] += 1\n",
    "            \n",
    "    return _hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13 µs, sys: 0 ns, total: 13 µs\n",
      "Wall time: 16.7 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'NOUN': 11,\n",
       " 'AUX': 10,\n",
       " 'ADV': 2,\n",
       " 'VERB': 8,\n",
       " 'DET': 6,\n",
       " 'SPACE': 5,\n",
       " 'ADJ': 2,\n",
       " 'CCONJ': 2,\n",
       " 'ADP': 1,\n",
       " 'PROPN': 3,\n",
       " 'PART': 4,\n",
       " 'SCONJ': 1,\n",
       " 'PRON': 1}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos = [p[1] for p in libnlp.parts_of_speech(doc)]\n",
    "%time pos_hash(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 267 µs, total: 267 µs\n",
      "Wall time: 274 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Explosions', 'NOUN'),\n",
       " ('will', 'AUX'),\n",
       " ('continually', 'ADV'),\n",
       " ('shake', 'VERB'),\n",
       " ('the', 'DET'),\n",
       " ('earth', 'NOUN'),\n",
       " ('\\n    ', 'SPACE'),\n",
       " ('Radiated', 'NOUN'),\n",
       " ('robot', 'NOUN'),\n",
       " ('men', 'NOUN'),\n",
       " ('will', 'AUX'),\n",
       " ('stalk', 'VERB'),\n",
       " ('each', 'DET'),\n",
       " ('other', 'ADJ'),\n",
       " ('\\n    ', 'SPACE'),\n",
       " ('The', 'DET'),\n",
       " ('rich', 'ADJ'),\n",
       " ('and', 'CCONJ'),\n",
       " ('the', 'DET'),\n",
       " ('chosen', 'VERB'),\n",
       " ('will', 'AUX'),\n",
       " ('watch', 'VERB'),\n",
       " ('from', 'ADP'),\n",
       " ('space', 'NOUN'),\n",
       " ('platforms', 'NOUN'),\n",
       " ('\\n    ', 'SPACE'),\n",
       " ('Dante', 'PROPN'),\n",
       " (\"'s\", 'PART'),\n",
       " ('Inferno', 'PROPN'),\n",
       " ('will', 'AUX'),\n",
       " ('be', 'AUX'),\n",
       " ('made', 'VERB'),\n",
       " ('to', 'PART'),\n",
       " ('look', 'VERB'),\n",
       " ('like', 'SCONJ'),\n",
       " ('a', 'DET'),\n",
       " ('children', 'NOUN'),\n",
       " (\"'s\", 'PART'),\n",
       " ('playground', 'NOUN'),\n",
       " ('\\n    ', 'SPACE'),\n",
       " ('The', 'DET'),\n",
       " ('sun', 'NOUN'),\n",
       " ('will', 'AUX'),\n",
       " ('not', 'PART'),\n",
       " ('be', 'AUX'),\n",
       " ('seen', 'VERB'),\n",
       " ('and', 'CCONJ'),\n",
       " ('it', 'PRON'),\n",
       " ('will', 'AUX'),\n",
       " ('always', 'ADV'),\n",
       " ('be', 'AUX'),\n",
       " ('night', 'NOUN'),\n",
       " ('\\n    ', 'SPACE'),\n",
       " ('Trees', 'PROPN'),\n",
       " ('will', 'AUX'),\n",
       " ('die', 'VERB')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time libnlp.parts_of_speech(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Noun Chunking\n",
    "This is probably magic.\n",
    "\n",
    "Noun chunking seems to work well in most cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 481 µs, sys: 20 µs, total: 501 µs\n",
      "Wall time: 510 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Explosions', 'NP'),\n",
       " ('the earth', 'NP'),\n",
       " ('Radiated robot men', 'NP'),\n",
       " ('space platforms', 'NP'),\n",
       " (\"Dante's Inferno\", 'NP'),\n",
       " (\"a children's playground\", 'NP'),\n",
       " ('The sun', 'NP'),\n",
       " ('it', 'NP'),\n",
       " ('night', 'NP'),\n",
       " ('Trees', 'NP')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time libnlp.noun_chunks(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Entity Detection\n",
    "\n",
    "Entity parsing seems to do better with larger models. `Dante's inferno` being classified as an organization could probably be improved with a dataset that has more contextual references. It did reasonably well without that context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 94 µs, sys: 0 ns, total: 94 µs\n",
      "Wall time: 111 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(\"Dante's Inferno\", 'ORG'), ('night', 'TIME')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time libnlp.entities(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "I have wrapped some functions as lambdas. This is purely for convenience. Python doesnt allow partial function application (without additional imports), and this is just a work around."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize = lambda corpra: libnlp.tokenize(nlp, corpra)\n",
    "topic_vector = lambda tokens: libnlp.topic_vector(nlp, tokens)\n",
    "topic_string = lambda vector: libnlp.topic_string(nlp, keys, vectors, vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Tokenize\n",
    "```\n",
    "\"a sentance\" -> [\"a\", \"sentance\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Explosions, will, continually, shake, the, earth, \n",
      "    , Radiated, robot, men, will, stalk, each, other, \n",
      "    , The, rich, and, the, chosen, will, watch, from, space, platforms, \n",
      "    , Dante, 's, Inferno, will, be, made, to, look, like, a, children, 's, playground, \n",
      "    , The, sun, will, not, be, seen, and, it, will, always, be, night, \n",
      "    , Trees, will, die]\n",
      "CPU times: user 204 ms, sys: 94 µs, total: 204 ms\n",
      "Wall time: 205 ms\n"
     ]
    }
   ],
   "source": [
    "%time tokens = tokenize(doc); print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Topic Vector\n",
    "```\n",
    "You shall know a word by the company it keeps - Firth\n",
    "```\n",
    "\n",
    "The topic vector is the average of the word vectors. This is not the best approximation a topic. A neural net with a labeled dataset would likely outperform this method.\n",
    "\n",
    "```\n",
    "( [1,2,3] + [6,5,4] ) * [0.5,0.5,0.5] = [3.5,3.5,3.5]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.03331937  0.02858579 -0.07996928 -0.0517877   0.01438936] ... len: 300\n",
      "CPU times: user 2.92 ms, sys: 120 µs, total: 3.04 ms\n",
      "Wall time: 6.59 ms\n"
     ]
    }
   ],
   "source": [
    "%time topic = topic_vector(tokens); print(f\"{topic[:5]} ... len: {len(topic)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Topic String\n",
    "\n",
    "The topic string is the word in our vocabulary that is closest to the topic vector.\n",
    "\n",
    "The closest word is found by calculating the cosine distance between the topic vector and every single vector in our vocabulary. The smallest cosine distance is chosen.\n",
    "\n",
    "This is still in numeric form. It is them used as a key to look up the string value in the vocab data struct.\n",
    "\n",
    "```\n",
    "[1.1,1.9,2.7,3.8] -> [1,2,3,4] -> \"joe\"\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 886 ms, sys: 740 ms, total: 1.63 s\n",
      "Wall time: 1.63 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'one'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time topic_string(topic)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
